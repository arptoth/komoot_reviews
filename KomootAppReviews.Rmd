---
title: "Why does people like Komoot in USA"
author: "Text Analysis based on 157 user reviews in US App Store. Árpád Tóth"
output: 
  html_document: 
    highlight: zenburn
    theme: yeti
    df_print: paged
    code_folding: hide
---


![](http://cdn.shopify.com/s/files/1/0306/9401/t/2/assets/logo.png?91405913226758837) 


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

 This report is a part of my job application for Data Analyst position at Komoot. 
 Job desscription is here: <http://https://www.komoot.com/jobs/data-analyst>). This is report is the "Doing something creative with komoot" part.
 
 
## What I did

 1. I scraped 157 app reviews from US App Store (by a simple node.js script)
 2. I did some exploratory data analysis
 3. I created a basic prediction for rating based on review texts
 4. I did sentiment analysis. What feelings and emotions are related with a review?
 5. Make recommendations how to improve user satisfaction in US
 
 
## Actionable insights

Based on text analysis I found the following information:

 1. People generally like Komoot app. The average rating is 4.2 in US. However, comparing the review numbers in Germany the penetration in other counties could be improved
 2. Most of the dissatisfaction are related to battery usage and crashes.
 3. The most unsatisfied veriosn is the !!!!
 4. ...


```{r importing, include=FALSE}
library(tidyverse)
library(ggplot2)
library(tidytext)
library(wordcloud)
library(caret)
library(glmnet)
library(h2o)
library(lime)
library(jsonlite)
```

```{r}

```



## Data import

 The node.js script scraped the reviews in JSON format. It adjusted manually firts because some key values were not claused by "". Afterthat I imported it by jsonlite library in R.

```{r pressure}
# Data import and cleaning ------------------------------------------------

# Read US App Store reviews about Komoot
reviews <- read_json("reviews.json")

# Translate to tibble
reviews <-  bind_rows(reviews)

reviews
```


## Let' explore the data

### What is the average rating in USA?


```{r}
# Average ratings of Komoot App in the US Store based on these 157 reviews
mean(reviews$score)

```

### Distributions of ratings
```{r, message=FALSE}
# Distributions of ratings
reviews %>%  ggplot(aes(score)) + geom_bar() + theme_minimal()
```


### Number of reviews grouped by version

```{r, message=FALSE}
version_counts <- reviews %>% select(version) %>% group_by(version) %>% summarise(Count=n()) %>% arrange(desc(Count))
version_counts
```


### Top 10 reviewed versions


```{r}
version_counts %>% 
  head() %>% 
  ggplot(aes(x=version, y=Count)) + 
  geom_bar(stat = "identity") +
  theme_minimal()
```


### Average ratings by version


```{r}
reviews %>% select(version, score) %>% group_by(version) %>% summarise(Mean=mean(score), Count=n()) %>% arrange(desc(Count))
```

## Text Analysis

### Who writes the longest review?

```{r}
word_data <- reviews %>% 
  select(userName, text) %>% 
  tidytext::unnest_tokens(word, text, token = "words")

word_count <- word_data %>% 
  group_by(userName) %>% 
  summarise(n_words = n_distinct(word))

# Top 10 reviewers by word count
word_count %>% arrange(desc(n_words))
```

## What did he write?

```{r}
reviews %>% select(userName,text) %>% filter(userName == "Giovanni xmilkcratex") %>% select(text)
```

## What are the most frequent words?

I excluded the stopwords like a, I, do not, etc.

```{r}
# most frequent words 
word_data %>%
  anti_join(get_stopwords()) %>%
  count(word, sort = TRUE)
```

Let's create a wordcloud from that.

```{r}
# wordclouds
word_data %>%
  anti_join(get_stopwords()) %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100))

```

## Title anylsis

Let's explore the titles too. Just the most frequent words, the words number by user and awordcloud.

```{r}
# Title Analysis
title_words <- reviews %>% 
  select(userName, title) %>% 
  tidytext::unnest_tokens(word, title, token = "words")


# Word counts in title by userName
title_count <- title_words %>% 
  group_by(userName) %>% 
  summarise(Count = n()) %>% 
  arrange(desc(Count))


title_count

# Most frequent words in titles
title_words %>% 
  anti_join(get_stopwords()) %>% 
  count(word, sort=T) %>% 
  with(wordcloud(word, n, max.words = 100))
```


## Can I predict ratings by review text itself?

First I had to create a sparse matrix to represents word counts by users. Let's review how it looks like. This is an excerpt which includes only 3 words: fun, bike and app. The userName and score columns are from the original table.

```{r}
sparse_matrix <- reviews %>% 
  select(userName, text) %>% 
  tidytext::unnest_tokens(word, text, token = "words") %>% 
  anti_join(get_stopwords()) %>%
  count(userName, word, sort = TRUE) %>% 
  cast_sparse(userName, word, n)

sparse_matrix <- as.data.frame(as.matrix(sparse_matrix))

sparse_matrix$userName <- rownames(sparse_matrix)

train_df <- left_join(x=sparse_matrix, y=reviews[,c("userName", "score")])

train_df %>% select(userName, score, fun, bike, app) %>% as_tibble()

```


Using H2O I tried first Gradient Boosting Machine because we approximate a 1-5 scale. It could be also a multiclass classification.

```{r}
# Set seed because of reproducability
n_seed = 12345

# Create target and feature list
target = "score" # Result
features = setdiff(colnames(train_df), c("target", "userName"))


# Start a local H2O cluster (JVM)
h2o.init()

# H2O dataframe
h_data <-  as.h2o(train_df)


# Split Train/Test
h_split = h2o.splitFrame(h_data, ratios = 0.75, seed = n_seed)
h_train = h_split[[1]] # 75% for modelling
h_test = h_split[[2]] # 25% for evaluation




# Train a Default H2O GBM model
model_gbm = h2o.gbm(x = features,
                    y = target,
                    training_frame = h_train,
                    balance_classes = TRUE,
                    model_id = "my_gbm",
                    seed = n_seed)
print(model_gbm)


# Evaluate performance on test
h2o.performance(model_gbm, newdata = h_test)
```



